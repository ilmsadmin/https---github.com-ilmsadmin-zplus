apiVersion: v1
kind: Namespace
metadata:
  name: kafka
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: zookeeper-config
  namespace: kafka
data:
  init.sh: |
    #!/bin/bash
    set -e
    mkdir -p /data/zookeeper
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: kafka-config
  namespace: kafka
data:
  server.properties: |
    broker.id=${KAFKA_BROKER_ID}
    advertised.listeners=${KAFKA_ADVERTISED_LISTENERS}
    listener.security.protocol.map=${KAFKA_LISTENER_SECURITY_PROTOCOL_MAP}
    inter.broker.listener.name=${KAFKA_INTER_BROKER_LISTENER_NAME}
    zookeeper.connect=${KAFKA_ZOOKEEPER_CONNECT}
    log.dirs=/var/lib/kafka/data
    num.partitions=6
    default.replication.factor=3
    min.insync.replicas=2
    log.retention.hours=168
    log.segment.bytes=1073741824
    log.retention.check.interval.ms=300000
    auto.create.topics.enable=false
    delete.topic.enable=true
    transaction.state.log.replication.factor=3
    transaction.state.log.min.isr=2
    group.initial.rebalance.delay.ms=100
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: zookeeper
  namespace: kafka
spec:
  serviceName: zookeeper-headless
  replicas: 3
  selector:
    matchLabels:
      app: zookeeper
  template:
    metadata:
      labels:
        app: zookeeper
    spec:
      containers:
      - name: zookeeper
        image: confluentinc/cp-zookeeper:7.4.0
        ports:
        - containerPort: 2181
          name: client
        - containerPort: 2888
          name: server
        - containerPort: 3888
          name: leader-election
        env:
        - name: ZOOKEEPER_CLIENT_PORT
          value: "2181"
        - name: ZOOKEEPER_TICK_TIME
          value: "2000"
        - name: ZOOKEEPER_SERVER_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: ZOOKEEPER_SERVERS
          value: "zookeeper-0.zookeeper-headless.kafka.svc.cluster.local:2888:3888;zookeeper-1.zookeeper-headless.kafka.svc.cluster.local:2888:3888;zookeeper-2.zookeeper-headless.kafka.svc.cluster.local:2888:3888"
        volumeMounts:
        - name: data
          mountPath: /var/lib/zookeeper/data
        - name: log
          mountPath: /var/lib/zookeeper/log
        livenessProbe:
          exec:
            command:
            - bash
            - -c
            - echo ruok | nc localhost 2181 | grep imok
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
        readinessProbe:
          exec:
            command:
            - bash
            - -c
            - echo ruok | nc localhost 2181 | grep imok
          initialDelaySeconds: 10
          periodSeconds: 10
          timeoutSeconds: 5
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
      securityContext:
        runAsUser: 1000
        fsGroup: 1000
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: standard
      resources:
        requests:
          storage: 10Gi
  - metadata:
      name: log
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: standard
      resources:
        requests:
          storage: 10Gi
---
apiVersion: v1
kind: Service
metadata:
  name: zookeeper-headless
  namespace: kafka
spec:
  clusterIP: None
  ports:
  - port: 2181
    name: client
  - port: 2888
    name: server
  - port: 3888
    name: leader-election
  selector:
    app: zookeeper
---
apiVersion: v1
kind: Service
metadata:
  name: zookeeper
  namespace: kafka
spec:
  ports:
  - port: 2181
    name: client
  selector:
    app: zookeeper
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
  namespace: kafka
spec:
  serviceName: kafka-headless
  replicas: 3
  selector:
    matchLabels:
      app: kafka
  template:
    metadata:
      labels:
        app: kafka
    spec:
      containers:
      - name: kafka
        image: confluentinc/cp-kafka:7.4.0
        ports:
        - containerPort: 9092
          name: kafka
        - containerPort: 9093
          name: kafka-internal
        env:
        - name: KAFKA_BROKER_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
              apiVersion: v1
          # Extract ordinal from pod name
        - name: ORDINAL
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: BROKER_ID
          value: "$(echo ${ORDINAL} | awk -F'-' '{print $2}')"
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        - name: KAFKA_ZOOKEEPER_CONNECT
          value: "zookeeper:2181"
        - name: KAFKA_LISTENER_SECURITY_PROTOCOL_MAP
          value: "INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT"
        - name: KAFKA_ADVERTISED_LISTENERS
          value: "INTERNAL://$(POD_IP):9093,EXTERNAL://kafka-$(BROKER_ID).kafka-headless.kafka.svc.cluster.local:9092"
        - name: KAFKA_INTER_BROKER_LISTENER_NAME
          value: "INTERNAL"
        - name: KAFKA_AUTO_CREATE_TOPICS_ENABLE
          value: "false"
        - name: KAFKA_DELETE_TOPIC_ENABLE
          value: "true"
        - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
          value: "3"
        - name: KAFKA_DEFAULT_REPLICATION_FACTOR
          value: "3"
        - name: KAFKA_MIN_INSYNC_REPLICAS
          value: "2"
        - name: KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
          value: "3"
        - name: KAFKA_TRANSACTION_STATE_LOG_MIN_ISR
          value: "2"
        volumeMounts:
        - name: data
          mountPath: /var/lib/kafka/data
        livenessProbe:
          exec:
            command:
            - sh
            - -c
            - kafka-topics --bootstrap-server localhost:9092 --list
          initialDelaySeconds: 60
          periodSeconds: 30
          timeoutSeconds: 15
        readinessProbe:
          exec:
            command:
            - sh
            - -c
            - kafka-topics --bootstrap-server localhost:9092 --list
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
      securityContext:
        runAsUser: 1000
        fsGroup: 1000
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: standard
      resources:
        requests:
          storage: 50Gi
---
apiVersion: v1
kind: Service
metadata:
  name: kafka-headless
  namespace: kafka
spec:
  clusterIP: None
  ports:
  - port: 9092
    name: kafka
  selector:
    app: kafka
---
apiVersion: v1
kind: Service
metadata:
  name: kafka
  namespace: kafka
spec:
  ports:
  - port: 9092
    name: kafka
  selector:
    app: kafka
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: schema-registry
  namespace: kafka
spec:
  replicas: 2
  selector:
    matchLabels:
      app: schema-registry
  template:
    metadata:
      labels:
        app: schema-registry
    spec:
      containers:
      - name: schema-registry
        image: confluentinc/cp-schema-registry:7.4.0
        ports:
        - containerPort: 8081
        env:
        - name: SCHEMA_REGISTRY_HOST_NAME
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        - name: SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS
          value: "kafka:9092"
        - name: SCHEMA_REGISTRY_LISTENERS
          value: "http://0.0.0.0:8081"
        - name: SCHEMA_REGISTRY_KAFKASTORE_TOPIC_REPLICATION_FACTOR
          value: "3"
        livenessProbe:
          httpGet:
            path: /subjects
            port: 8081
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /subjects
            port: 8081
          initialDelaySeconds: 10
          periodSeconds: 10
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
---
apiVersion: v1
kind: Service
metadata:
  name: schema-registry
  namespace: kafka
spec:
  ports:
  - port: 8081
    targetPort: 8081
  selector:
    app: schema-registry
---
apiVersion: batch/v1
kind: Job
metadata:
  name: kafka-topic-setup
  namespace: kafka
spec:
  ttlSecondsAfterFinished: 600
  template:
    spec:
      containers:
      - name: kafka-topic-setup
        image: confluentinc/cp-kafka:7.4.0
        command:
        - /bin/bash
        - -c
        - |
          # Wait for Kafka to be ready
          echo "Waiting for Kafka to be ready..."
          cub kafka-ready -b kafka:9092 3 300
          
          # Create topics for event streams
          echo "Creating event stream topics..."
          kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic tenant.events --partitions 6 --replication-factor 3 --config min.insync.replicas=2
          kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic user.events --partitions 6 --replication-factor 3 --config min.insync.replicas=2
          kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic billing.events --partitions 4 --replication-factor 3 --config min.insync.replicas=2
          kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic notification.events --partitions 4 --replication-factor 3 --config min.insync.replicas=2
          kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic file.events --partitions 3 --replication-factor 3 --config min.insync.replicas=2
          kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic analytics.events --partitions 3 --replication-factor 3 --config min.insync.replicas=2
          
          # Create dead letter queue topics
          echo "Creating DLQ topics..."
          kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic tenant.events.dlq --partitions 3 --replication-factor 3 --config min.insync.replicas=2
          kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic user.events.dlq --partitions 3 --replication-factor 3 --config min.insync.replicas=2
          kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic billing.events.dlq --partitions 3 --replication-factor 3 --config min.insync.replicas=2
          kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic notification.events.dlq --partitions 3 --replication-factor 3 --config min.insync.replicas=2
          kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic file.events.dlq --partitions 3 --replication-factor 3 --config min.insync.replicas=2
          kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic analytics.events.dlq --partitions 3 --replication-factor 3 --config min.insync.replicas=2
          
          # List all topics
          echo "Listing topics..."
          kafka-topics --bootstrap-server kafka:9092 --list
      restartPolicy: Never
  backoffLimit: 3
